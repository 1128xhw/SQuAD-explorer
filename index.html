<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><meta charset="utf-8"><title>The Stanford Question Answering Dataset</title><meta name="description" content="Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. With 107,785 question-answer pairs on 536 articles, SQuAD is significantly larger than previous reading comprehension datasets."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.jpg"><link rel="image_src" type="image/jpeg" href="/SQuAD-explorer/logo.jpg"><link rel="shortcut icon" href="/SQuAD-explorer/favicon.ico" type="image/x-icon"><link rel="icon" href="/SQuAD-explorer/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/SQuAD-explorer/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/SQuAD-explorer/stylesheets/layout.css"><link rel="stylesheet" href="/SQuAD-explorer/stylesheets/index.css"><link href="https://cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css"><script src="/SQuAD-explorer/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="/SQuAD-explorer/">Home</a></li><li><a href="/SQuAD-explorer/explore.html">Explore</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/SQuAD-explorer/">SQuAD</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle">SQuAD</h1><h2 id="appSubtitle">The Stanford Question Answering Dataset</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-8 col-md-offset-2"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is SQuAD?</h2></div><p> <span style="white-space: nowrap"><b>S</b>tanford <b>Qu</b>estion <b>A</b>nswering <b>D</b>ataset (SQuAD) </span>is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or <i>span</i>, from the corresponding reading passage. With over 100k question-answer pairs on 500+ articles, SQuAD is significantly larger than previous reading comprehension datasets.</p><ul class="list-inline"><li><a class="btn actionBtn inverseBtn" href="http://arxiv.org/abs/1606.05250">Read Our Paper</a></li></ul><div class="spacer"></div><div class="infoHeadline"><h2>What does SQuAD look like?</h2></div><p>You can browse through v1.1 of the development and training sets.</p><ul class="list-inline"><li><a class="btn actionBtn" href="/SQuAD-explorer/explore/1.1/train/">Explore v1.1 Train Set</a></li><li><a class="btn actionBtn" href="/SQuAD-explorer/explore/1.1/dev/">Explore v1.1 Dev Set</a></li></ul><div class="spacer"></div><div class="infoHeadline"><h2>How do I download the dataset?</h2></div><p>You can download v1.1 of the training and development sets. </p><ul class="list-inline" id="downloadList"><li><a class="btn actionBtn inverseBtn" href="/SQuAD-explorer/dataset/train-v1.1.json" download>Training Set v1.1 (30 MB)</a></li><li><a class="btn actionBtn inverseBtn" href="/SQuAD-explorer/dataset/dev-v1.1.json" download>Dev Set v1.1 (5 MB)</a></li></ul><p>We also have a hidden test set. To evaluate your models on the test set, please get in contact with us.</p><div class="spacer"></div><div class="infoHeadline"><h2>What is the best model performance?</h2></div><p>Our best model (detailed in our  <a href="http://arxiv.org/abs/1606.05250">paper</a>) achieves an F1 score of <b>51.0%</b>.
We expect future models to close the gap to the human performance of <b>86.8%</b> . Note that these results are on v1.0 of the dataset.</p><table class="table" id="performanceTable"><tr><th>Model</th><th>Dev F1</th><th>Test F1</th></tr><tr class="active"><td>Human Performance</td><td>90.5%</td><td>86.8%</td></tr><tr><td><a href="http://arxiv.org/abs/1606.05250">Rajpurkar et al. '16</a> Logistic Regression</td><td>51.0% </td><td>51.0%</td></tr><tr><td><b>Beat our model?</b> Contact us to get on the leaderboard.</td><td>?</td><td>?</td></tr></table><ul class="list-inline"><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/worksheets/0x62eefc3e64e04430a1a24785a9293fff/">CodaLab Worksheet</a></li></ul><div class="spacer"></div><div class="infoHeadline"><h2>Have Questions?</h2></div><p>Because SQuAD is an ongoing effort, we expect the dataset to evolve.</p><p>To keep up to date with major changes to the dataset, please subscribe:</p><div id="mc_embed_signup"><form class="validate" id="mc-embedded-subscribe-form" action="//google.us13.list-manage.com/subscribe/post?u=1842e6560d6e10316b4e1aaf5&amp;id=76586bdcf4" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate=""><div id="mc_embed_signup_scroll"><input class="email" id="mce-EMAIL" type="email" value="" name="EMAIL" placeholder="email address" required=""><div style="position: absolute; left: -5000px" aria-hidden="true"><input type="text" name="b_1842e6560d6e10316b4e1aaf5_76586bdcf4" tabindex="-1" value=""></div><div class="clear"><input class="button" id="mc-embedded-subscribe" type="submit" value="Subscribe" name="subscribe"></div></div></form></div><p> The dataset is distributed under the  <a href="http://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA 4.0</a> license.</p><p> Ask us questions through  <a href="https://groups.google.com/forum/#!forum/squad-stanford-qa">google groups </a>or at <a href="mailto:pranavsr@stanford.edu">pranavsr@stanford.edu</a>.</p></div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://stanford-qa.com" data-text="The Stanford Question Answering Dataset - 100,000+ questions for reading comprehension" data-via="stanfordnlp" data-size="large" data-hashtags="SQuAD">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><a class="github-button" href="https://github.com/rajpurkar/SQuAD-explorer" data-style="mega" data-count-href="/SQuAD-explorer/rajpurkar/SQuAD-explorer" data-count-api="/repos/rajpurkar/SQuAD-explorer#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star SQuAD-explorer on GitHub">Star on Github</a></div></div></div></div></div></div><nav class="navbar navbar-default navbar-static-bottom footer"><div class="container clearfix"><div class="rightNav"><div><ul class="nav navbar-nav navbar-right"><li><a href="/SQuAD-explorer/">SQuAD 2016</a></li><li><a href="http://nlp.stanford.edu">Stanford NLP Group</a></li></ul></div></div></div></nav><script src="/SQuAD-explorer/bower_components/jquery/dist/jquery.min.js"></script><script src="/SQuAD-explorer/bower_components/bootstrap/dist/js/bootstrap.min.js"></script><script async defer src="https://buttons.github.io/buttons.js"></script></body></html>